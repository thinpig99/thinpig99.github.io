---
title: "배깅과 부스팅의 !"
date: 2021-04-26 14:57:28 -0400
categories: MachineLearning
---

자, 간단하게 말할게.

 

배깅은 랜덤포레스트.

부스팅은 그라디언트 부스팅.

 

배깅은 독립적.

부스팅은 의존적.

 

배깅은 병렬적.

부스팅은 순차적. 혹은 직렬적.

 

-----------------------------------------------------------------------------------------------------

 

랜덤포레스트가 작동하는 원리가 뭐냐?

표본 샘플이 주어지면, 해당 표본에서 랜덤 샘플링을 통해서 여러 개의 모델을 학습시킨다.

이때 복원추출을 한다. 그렇기 때문에 각각의 모델(디시젼 트리)는 독립적이다.

이렇게 독립적인 모델(디시젼 트리)의 학습 결과를 모아서 앙상블 하는 게 랜덤포레스트고 이러한 방식을 배깅이라고 한다.

Bootstrap aggreagting. 영어를 해석하면 이해가 쉽다.

 

 

결국 배깅의 특징은 이렇다.

1. 모델이 서로 독립적이라는 것.

2. 모델 학습이 병렬적.

3. 또 하나 중요한 것은, 표본을 반복적으로 복원추출해서 모델을 만들기 때문에, (이는 k-fold와 얼추 비슷한 매커니즘이다.) 적은 표본 샘플을 가지더라도 오버피팅을 방지하고 일반화된 성능을 낼 수 있다는 것이다. (사실 애초에 랜덤 포레스트는 디시젼 트리의 오버피팅을 개선하기 위해 나온 모델이다.)

 

 

------------------------------------------------------------------------------------------------------------------

 

자 그럼 부스팅은 뭐냐?

부스팅도 똑같습니다. 배깅처럼 랜덤 샘플링을 통해 여러 모델을 학습 시킵니다.

다른 점은 모델이 학습 할 때 서로 독립적인 게 아니라, 순차적으로 학습을 한다는 것입니다.

총 5개의 모델을 앙상블한다고 하면, 1번 모델의 오차를 개선하는 방향으로 2번 모델을 학습, 2번 모델의 오차를 개선하는 방향으로 3번을 학습...이렇게 마지막까지 갑니다.

그래서 시간은 오래걸리지만 일반적으로 더 강력한 성능을 냅니다.

 

1. 각 모델이 의존적이다.

2. 모델 학습이 순차적이다.

 

-----------------------------------------------------------------------------------------------------------

 

더 자세히 알고 싶으면 아래 링크들을 들어가보면 아주 잘 설명되어 있다.

blog.naver.com/baek2sm/221771893509

data-matzip.tistory.com/entry/%EC%95%99%EC%83%81%EB%B8%94-%EA%B8%B0%EB%B2%95-%EC%A0%95%EB%A6%AC-1-%EC%95%99%EC%83%81%EB%B8%94Ensemble-%EA%B8%B0%EB%B2%95%EA%B3%BC-%EB%B0%B0%EA%B9%85Bagging-%EB%B6%80%EC%8A%A4%ED%8C%85Boosting-%EC%8A%A4%ED%85%8C%EC%9D%B4%ED%82%B9Stacking
